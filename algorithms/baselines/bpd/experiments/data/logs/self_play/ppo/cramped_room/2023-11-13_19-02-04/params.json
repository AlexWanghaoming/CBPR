{
  "callbacks": "<class 'bpd.envs.overcooked.OvercookedCallbacks'>",
  "clip_param": 0.05,
  "custom_eval_function": "<function build_overcooked_eval_function.<locals>._evaluate at 0x7f574a3f3320>",
  "entropy_coeff_schedule": [
    [
      0,
      0.2
    ],
    [
      3000000.0,
      0.001
    ]
  ],
  "env": "overcooked_multi_agent",
  "env_config": {
    "env_params": {
      "horizon": 400,
      "mlam_params": {
        "counter_drop": [],
        "counter_goals": [],
        "counter_pickup": [],
        "same_motion_goals": true,
        "start_orientations": false,
        "wait_allowed": false
      }
    },
    "mdp_params": {
      "layout_name": "cramped_room",
      "rew_shaping_params": {
        "DISH_DISP_DISTANCE_REW": 0,
        "DISH_PICKUP_REWARD": 3,
        "PLACEMENT_IN_POT_REW": 3,
        "POT_DISTANCE_REW": 0,
        "SOUP_DISTANCE_REW": 0,
        "SOUP_PICKUP_REWARD": 5
      }
    },
    "multi_agent_params": {
      "action_rewards": [
        0,
        0,
        0,
        0,
        0,
        0
      ],
      "bc_schedule": [
        [
          0,
          0
        ],
        [
          Infinity,
          0
        ]
      ],
      "extra_rew_shaping": {
        "dish_dispense": 0,
        "onion_dispense": 0
      },
      "no_regular_reward": false,
      "reward_shaping_factor": 1.0,
      "reward_shaping_horizon": 2500000.0,
      "share_dense_reward": false,
      "use_phi": false
    }
  },
  "evaluation_interval": 50,
  "framework": "torch",
  "gamma": 0.99,
  "grad_clip": 0.1,
  "input": "sampler",
  "input_evaluation": [],
  "kl_coeff": 0.2,
  "lambda": 0.98,
  "lr": 0.001,
  "multiagent": {
    "policies": {
      "ppo": [
        null,
        "Box([[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]]\n\n [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]]\n\n [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]]\n\n [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]]\n\n [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]\n  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n   0. 0. 0.]]], [[[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]]\n\n [[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]]\n\n [[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]]\n\n [[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]]\n\n [[inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]\n  [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n   inf inf inf inf inf inf inf inf inf]]], (5, 4, 26), float32)",
        "Discrete(6)",
        {
          "model": {
            "custom_model": "overcooked_ppo_model",
            "custom_model_config": {
              "num_conv_layers": 3,
              "num_filters": 25,
              "num_hidden_layers": 3,
              "size_hidden_layers": 64,
              "split_backbone": false
            },
            "lstm_cell_size": 256,
            "max_seq_len": 400,
            "use_attention": false,
            "use_lstm": false,
            "vf_share_layers": false
          }
        }
      ]
    },
    "policies_to_train": [
      "ppo"
    ],
    "policy_mapping_fn": "<function <lambda> at 0x7f574a3f33b0>"
  },
  "num_gpus": 1,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 8,
  "num_workers": 2,
  "rollout_fragment_length": 400,
  "seed": 0,
  "sgd_minibatch_size": 2000,
  "train_batch_size": 12000,
  "vf_loss_coeff": 0.0001
}