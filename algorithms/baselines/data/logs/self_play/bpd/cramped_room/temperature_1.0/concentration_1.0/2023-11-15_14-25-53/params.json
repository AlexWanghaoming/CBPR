{
  "callbacks": "<class 'bpd.envs.overcooked.OvercookedCallbacks'>",
  "clip_param": 0.05,
  "custom_eval_function": "<function build_overcooked_eval_function.<locals>._evaluate at 0x7f7cd12ce9e0>",
  "entropy_coeff_schedule": [
    [
      0,
      0.2
    ],
    [
      3000000.0,
      0.001
    ]
  ],
  "env": "latent_wrapper",
  "env_config": {
    "agents_with_latent": "{'ppo_1', 'ppo_0'}",
    "env": "overcooked_multi_agent",
    "env_config": {
      "env_params": {
        "horizon": 400,
        "mlam_params": {
          "counter_drop": [],
          "counter_goals": [],
          "counter_pickup": [],
          "same_motion_goals": true,
          "start_orientations": false,
          "wait_allowed": false
        }
      },
      "mdp_params": {
        "layout_name": "cramped_room",
        "rew_shaping_params": {
          "DISH_DISP_DISTANCE_REW": 0,
          "DISH_PICKUP_REWARD": 3,
          "PLACEMENT_IN_POT_REW": 3,
          "POT_DISTANCE_REW": 0,
          "SOUP_DISTANCE_REW": 0,
          "SOUP_PICKUP_REWARD": 5
        }
      },
      "multi_agent_params": {
        "action_rewards": [
          0,
          0,
          0,
          0,
          0,
          0
        ],
        "bc_schedule": [
          [
            0,
            0
          ],
          [
            Infinity,
            0
          ]
        ],
        "extra_rew_shaping": {
          "dish_dispense": 0,
          "onion_dispense": 0
        },
        "no_regular_reward": false,
        "reward_shaping_factor": 1.0,
        "reward_shaping_horizon": 2500000.0,
        "share_dense_reward": false,
        "use_phi": false
      }
    },
    "episodes_per_latent": 7,
    "latent_dist": "<function <lambda> at 0x7f7cd1347c20>",
    "use_tuple": true
  },
  "evaluation_interval": 100000000000000000000,
  "framework": "torch",
  "gamma": 0.99,
  "grad_clip": 0.1,
  "input": "sampler",
  "input_evaluation": [],
  "kl_coeff": 0.2,
  "lambda": 0.98,
  "latent_size": 10,
  "lr": 0.001,
  "multiagent": {
    "policies": {
      "ppo": [
        null,
        "Tuple(Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n inf inf inf inf inf inf], (96,), float32), Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf], (10,), float32))",
        "Discrete(6)",
        {
          "model": {
            "custom_model": "overcooked_ppo_distribution_model",
            "custom_model_config": {
              "discriminate_sequences": false,
              "discriminator_input_smoothing_std": 0,
              "discriminator_scale": 1,
              "ignore_latents": false,
              "latent_size": 10,
              "num_conv_layers": 3,
              "num_filters": 25,
              "num_hidden_layers": 3,
              "pointless_discriminator_latent_input": false,
              "size_hidden_layers": 64,
              "split_backbone": false,
              "use_latent_attention": false
            },
            "lstm_cell_size": 256,
            "max_seq_len": 400,
            "use_attention": false,
            "use_lstm": false,
            "vf_share_layers": false
          }
        }
      ]
    },
    "policies_to_train": [
      "ppo"
    ],
    "policy_mapping_fn": "<function <lambda> at 0x7f7cd1339a70>"
  },
  "num_gpus": 1,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 8,
  "num_workers": 2,
  "prior_concentration": 1.0,
  "rollout_fragment_length": 400,
  "seed": 0,
  "sgd_minibatch_size": 2000,
  "temperature": 1.0,
  "train_batch_size": 12000,
  "vf_loss_coeff": 0.0001
}