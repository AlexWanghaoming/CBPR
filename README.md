
## Introduction ğŸ¥˜
Popular RL algorithms based [overcooked_ai](https://github.com/HumanCompatibleAI/overcooked_ai) environment (6bde8b27b5a1dcdba571e8f53d98c6fc836eca8c).
Overcooked-AI is a benchmark environment for fully cooperative human-AI task performance, based on the wildly popular video game [Overcooked](http://www.ghosttowngames.com/overcooked/).


## Code Structure Overview ğŸ—º
`bc/`:
- `bc_hh.py`: ç”¨è¡Œä¸ºå…‹éš†æ‹Ÿåˆå½“å‰layoutä¸‹çš„äººç±»ç­–ç•¥
- `bc_hh_meta_task.py`: æ ¹æ®key stateåˆ’åˆ†äººç±»è½¨è¿¹,åˆ†åˆ«æ‹Ÿåˆä¸åŒçš„meta-task models

`algorithms/`:
- `bcp.py`: æ ¹æ®BCæ¨¡å‹è®­ç»ƒBCPæ¨¡å‹
- `bpr_NN.py`å’Œ`bpr_gp.py`: å¤ç°è®ºæ–‡ *Efficient Bayesian Policy Reuse With a Scalable Observation Model in Deep Reinforcement Learning* ç®—æ³•
- `mtp.py`: è®­ç»ƒä¸ä¸åŒmeta-task modelsåˆä½œçš„BCPæ¨¡å‹
- `okr.py`: å¤ç°è®ºæ–‡ *Accurate policy detection and efficient knowledge reuse against multi-strategic opponents*ç®—æ³•
- `sp_ppo.py`:  åŸºäºPPOçš„è‡ªåšå¼ˆè®­ç»ƒ, state normalization æ–¹æ³•æ¥è‡ª elegantRL
- `sp_sac.py`: åŸºäºSACçš„è‡ªåšå¼ˆè®­ç»ƒï¼Œè¶…å‚æ•°è®¾ç½® :
`{'hidden_dim': 64, 'lr': 1e-4, 'tau': 0.005, 'adaptive_alpha': True, 'clip_grad_norm': 0.1, 'use_lr_decay': False, 'buffer_size': 1e6, 'batch_size': 256}`

`state_trans_func/`:
- `collect_trajs.py`: æ”¶é›†æ¯ä¸€ç§meta-taskçš„è½¨è¿¹
- `GP_GPy.py`: ç”¨GPyæ‹Ÿåˆ ä¸åŒmeta-tasksçš„çŠ¶æ€è½¬ç§»å‡½æ•°ï¼ˆå·²å¼ƒç”¨ï¼‰
- `GP_gpytorch.py`: ç”¨gpytorchæ‹Ÿåˆ ä¸åŒmeta-tasksçš„çŠ¶æ€è½¬ç§»å‡½æ•°
- `NN.py`: ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆä¸åŒmeta-tasksçš„çŠ¶æ€è½¬ç§»å‡½æ•°

`src/overcooked_ai_py/` contains:
`mdp/`:
- `overcooked_mdp.py`: main Overcooked game logic
- `overcooked_env.py`: environment classes built on top of the Overcooked mdp
- `layout_generator.py`: functions to generate random layouts programmatically


